{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2aa8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "import  speech_recognition as sr\n",
    "\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "from moviepy.editor import *\n",
    "\n",
    "from tkinter import filedialog\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "from utils import CvFpsCalc\n",
    "from model import KeyPointClassifier\n",
    "from model import PointHistoryClassifier\n",
    "\n",
    "import gtts\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "import datetime\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "import numpy as np\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import cv2\n",
    "\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('voice',\"HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\MSTTS_V110_arEG_Hoda\")\n",
    "\n",
    "\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "## Make canvas and set the color\n",
    "img = np.zeros((200,400,3),np.uint8)\n",
    "\n",
    "b,g,r,a = 0,255,0,0\n",
    "\n",
    "\n",
    "## Use simsum.ttc to write عربى.\n",
    "fontpath = \"alfont_com_arial-1.ttf\"\n",
    "font = ImageFont.truetype(fontpath, 32)\n",
    "img_pil = Image.fromarray(img)\n",
    "draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "\n",
    "labels = [\"ا\",\"ب\",\"ت\",\"ث\",\"ج\",\"ح\",\"خ\",\"د\",\"ذ\",\"ر\",\"ز\",\"س\",\"ش\",\"ص\",\"ض\",\"ط\",\"ظ\",\"ع\",\"غ\",\"ف\",\"ق\",\"ك\",\"ل\",\"م\",\"ن\",\"ه\",\"و\",\"ء\",\"ة\",\"ال\",\"ي\",\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f35fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help='cap width', type=int, default=960)\n",
    "    parser.add_argument(\"--height\", help='cap height', type=int, default=540)\n",
    "\n",
    "    parser.add_argument('--use_static_image_mode', action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help='min_detection_confidence',\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=int,\n",
    "                        default=0.5)\n",
    "   # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc6b3696",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    import tkinter as tk\n",
    "    global index\n",
    "    global Word\n",
    "    \n",
    "    arr=\"\"\n",
    "    Word=\"\"\n",
    "    temp=[]\n",
    "    arr2=[]\n",
    "    c=0\n",
    "    delayCount1=0\n",
    "    delayCount2=0\n",
    "    e=\"\"\n",
    "    wrd=\"\"\n",
    "    #var=StringVar()\n",
    "    # Argument parsing #################################################################\n",
    "    args = get_args()\n",
    "\n",
    "    cap_device = args.device\n",
    "    cap_width = args.width\n",
    "    cap_height = args.height\n",
    "\n",
    "    use_static_image_mode = args.use_static_image_mode\n",
    "    min_detection_confidence = args.min_detection_confidence\n",
    "    min_tracking_confidence = args.min_tracking_confidence\n",
    "\n",
    "    use_brect = True\n",
    "\n",
    "    # Camera preparation ###############################################################\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "\n",
    "    # Model load #############################################################\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    point_history_classifier = PointHistoryClassifier()\n",
    "\n",
    "    # Read labels ###########################################################\n",
    "    with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "              encoding='utf-8-sig') as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [\n",
    "            row[0] for row in keypoint_classifier_labels\n",
    "        ]\n",
    "    with open(\n",
    "            'model/point_history_classifier/point_history_classifier_label.csv',\n",
    "            encoding='utf-8-sig') as f:\n",
    "        point_history_classifier_labels = csv.reader(f)\n",
    "        point_history_classifier_labels = [\n",
    "            row[0] for row in point_history_classifier_labels\n",
    "        ]\n",
    "\n",
    "    # FPS Measurement ########################################################\n",
    "    cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "    # Coordinate history #################################################################\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "\n",
    "    # Finger gesture history ################################################\n",
    "    finger_gesture_history = deque(maxlen=history_length)\n",
    "\n",
    "    #  ########################################################################\n",
    "    mode = 0\n",
    "    \n",
    "    while True:\n",
    "        fps = cvFpsCalc.get()\n",
    "\n",
    "        # Process Key (ESC: end) #################################################\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        number, mode = select_mode(key, mode)\n",
    "\n",
    "        # Camera capture #####################################################\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)  # Mirror display\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        # Detection implementation #############################################################\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                  results.multi_handedness):\n",
    "                # Bounding box calculation\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                # Landmark calculation\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # Conversion to relative coordinates / normalized coordinates\n",
    "                pre_processed_landmark_list = pre_process_landmark(\n",
    "                    landmark_list)\n",
    "                pre_processed_point_history_list = pre_process_point_history(\n",
    "                    debug_image, point_history)\n",
    "                # Write to the dataset file\n",
    "                logging_csv(number, mode, pre_processed_landmark_list,\n",
    "                            pre_processed_point_history_list)\n",
    "\n",
    "                # Hand sign classification\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "                if hand_sign_id == \"Not applicable\":  # Point gesture\n",
    "                    point_history.append(landmark_list[8])\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                # Finger gesture classification\n",
    "                finger_gesture_id = 0\n",
    "                point_history_len = len(pre_processed_point_history_list)\n",
    "                if point_history_len == (history_length * 2):\n",
    "                    finger_gesture_id = point_history_classifier(\n",
    "                        pre_processed_point_history_list)\n",
    "\n",
    "                # Calculates the gesture IDs in the latest detection\n",
    "                finger_gesture_history.append(finger_gesture_id)\n",
    "                most_common_fg_id = Counter(\n",
    "                    finger_gesture_history).most_common()\n",
    "\n",
    "                # Drawing part\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                )\n",
    "                \n",
    "                import tkinter as tk                \n",
    "                if (hand_sign_id >=0 and hand_sign_id < 32):\n",
    "                    e=''.join(labels[hand_sign_id])\n",
    "                    Word=Word+labels[hand_sign_id]      \n",
    "                    if  e ==labels[hand_sign_id]:\n",
    "                        c=c+1\n",
    "                        if(c==20):\n",
    "                            arr+=e\n",
    "                            c=0\n",
    "                    else:\n",
    "                        arr-=arr.join(e)\n",
    "                        arr=''.join(map(str, [v for i, v in enumerate(arr) if i == 0 or v != arr[i-2]]))\n",
    "                            \n",
    "                elif (hand_sign_id == 32):\n",
    "                    if(delayCount1<=10):\n",
    "                        delayCount1=delayCount1+1\n",
    "                    else:\n",
    "                        \n",
    "                        arr=arr[:-1]\n",
    "                        cv.waitKey(700)\n",
    "                        delayCount1=0\n",
    "                        var.set(arr)\n",
    "                        T.update_idletasks()\n",
    "                        \n",
    "                elif (hand_sign_id == 33):\n",
    "                    if(delayCount2<=20):\n",
    "                        delayCount2=delayCount2+1\n",
    "                    else:\n",
    "                        tts = gtts.gTTS(arr, lang=\"ar\")\n",
    "                        tts.save(\"h3.mp3\")\n",
    "                        playsound(\"h3.mp3\")\n",
    "                        os.remove('h3.mp3') \n",
    "                        delayCount2=0\n",
    "                print(arr)\n",
    "                print (Word)\n",
    "                arr=arr\n",
    "                var.set(arr)\n",
    "                T.update()\n",
    "                cv.waitKey(50)\n",
    "        \n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "       \n",
    "        debug_image = draw_point_history(debug_image, point_history)\n",
    "        debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "        # Screen reflection #############################################################\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "         \n",
    "        T.pack\n",
    "       \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if 48 <= key <= 57:  # 0 ~ 9\n",
    "        number = key - 48\n",
    "    if key == 110:  # n\n",
    "        mode = 0\n",
    "    if key == 107:  # k\n",
    "        mode = 1\n",
    "    if key == 104:  # h\n",
    "        mode = 2\n",
    "    return number, mode\n",
    "\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list, point_history_list):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 34):\n",
    "        csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number+30, *landmark_list])\n",
    "    if mode == 2 and (0 <= number <= 34):\n",
    "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *point_history_list])\n",
    "    return\n",
    "\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (150, 216, 242), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (150, 216, 242), 2)\n",
    "\n",
    "    # Key Points\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index == 0:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 1:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 2:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 3:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 4:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 5:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 6:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 7:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 8:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 9:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 10:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 11:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 12:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 13: \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 14:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 15: \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 16: \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 17:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 18:  \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 19: \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 20: \n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (75, 84, 188),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (59, 68, 121), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (59, 68, 121), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "                   cv.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_point_history(image, point_history):\n",
    "    for index, point in enumerate(point_history):\n",
    "        if point[0] != 0 and point[1] != 0:\n",
    "            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
    "                      (152, 251, 152), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info(image, fps, mode, number):\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= number <= 34:\n",
    "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0be1bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vedioSign():\n",
    "        r=sr.Recognizer()\n",
    "        with sr.Microphone() as src:\n",
    "            print('Say something....')\n",
    "            audio=r.listen(src)\n",
    "            t=r.recognize_google(audio,language='ar-AR')\n",
    "        \n",
    "        arr = list(t)\n",
    "        global T2\n",
    "        T2.destroy()\n",
    "        t=''.join(arr)\n",
    "        var = StringVar()    # create a string variable\n",
    "        var.set(t)      # set it to \"letter\"\n",
    "        T2= Label(root, textvariable = var,font =font2,fg='black',bg='#f2d896')\n",
    "        T2.place(relx=0.6, rely=0.150, anchor=NE)      \n",
    "        labels = [\"ا\",\"ب\",\"ت\",\"ث\",\"ج\",\"ح\",\"خ\",\"د\",\"ذ\",\"ر\",\"ز\",\"س\",\"ش\",\"ص\",\"ض\",\"ط\",\"ظ\",\"ع\",\"غ\",\"ف\",\"ق\",\"ك\",\"ل\",\"م\",\"ن\",\"ه\",\"و\",\"ء\",\"ة\",\"ال\",\"لا\",\"ى\",\" \"]\n",
    "\n",
    "        for index in range(len(arr)) :\n",
    "            if arr[index]==' ':\n",
    "                arr[index]='1'\n",
    "            elif arr[index]=='ا':\n",
    "                arr[index]='2'\n",
    "            elif arr[index]=='ب':\n",
    "                arr[index]='3'\n",
    "            elif arr[index]=='ت':\n",
    "                arr[index]='4'\n",
    "            elif arr[index]=='ث':\n",
    "                arr[index]='5'\n",
    "            elif arr[index]=='ج':\n",
    "                arr[index]='6'\n",
    "            elif arr[index]=='ح':\n",
    "                arr[index]='7'\n",
    "            elif arr[index]=='خ':\n",
    "                arr[index]='8'\n",
    "            elif arr[index]=='د':\n",
    "                arr[index]='9'\n",
    "            elif arr[index]=='ذ':\n",
    "                arr[index]='10'\n",
    "            elif arr[index]=='ر':\n",
    "                arr[index]='11'\n",
    "            elif arr[index]=='ز':\n",
    "                arr[index]='12'\n",
    "            elif arr[index]=='س':\n",
    "                arr[index]='13'\n",
    "            elif arr[index]=='ش':\n",
    "                arr[index]='14'\n",
    "            elif arr[index]=='ص':\n",
    "                arr[index]='15'\n",
    "            elif arr[index]=='ض':\n",
    "                arr[index]='16'\n",
    "            elif arr[index]=='ط':\n",
    "                arr[index]='17'\n",
    "            elif arr[index]=='ظ':\n",
    "                arr[index]='18'\n",
    "            elif arr[index]=='ع':\n",
    "                arr[index]='19'\n",
    "            elif arr[index]=='غ':\n",
    "                arr[index]='20'\n",
    "            elif arr[index]=='ف':\n",
    "                arr[index]='21'\n",
    "            elif arr[index]=='ق':\n",
    "                arr[index]='22'\n",
    "            elif arr[index]=='ك':\n",
    "                arr[index]='23'\n",
    "            elif arr[index]=='ل':\n",
    "                arr[index]='24'\n",
    "            elif arr[index]=='م':\n",
    "                arr[index]='25'\n",
    "            elif arr[index]=='ن':\n",
    "                arr[index]='26'\n",
    "            elif arr[index]=='ه':\n",
    "                arr[index]='27'\n",
    "            elif arr[index]=='و':\n",
    "                arr[index]='28'\n",
    "            elif arr[index]=='ء':\n",
    "                arr[index]='29'\n",
    "            elif arr[index]=='ة':\n",
    "                arr[index]='30'\n",
    "            elif arr[index]=='ي':\n",
    "                arr[index]='31'\n",
    "            elif arr[index]=='ئ':\n",
    "                arr[index]='33'\n",
    "            elif arr[index]=='ؤ':\n",
    "                arr[index]='34'\n",
    "\n",
    "        video=[]\n",
    "        for i in range(len(arr)) : \n",
    "            video.append(ImageClip('%s.jpg' %str(arr[i])).set_duration(2))\n",
    "        final_clip = concatenate_videoclips(video, method='compose')\n",
    "        final_clip.write_videofile(\"merge.mp4\", fps=12, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "        \"\"\" pauses and plays \"\"\"\n",
    "        vid_player.load('merge.mp4')\n",
    "        vid_player.play()\n",
    "         \n",
    "\n",
    "\n",
    "def showvedio():\n",
    "    cap = cv2.VideoCapture('merge.mp4')\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "      # Display the resulting frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "      # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Break the loop\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # When everything done, release\n",
    "    # the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    os.remove('merge.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d63145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_duration(event):\n",
    "    \"\"\" updates the duration after finding the duration \"\"\"\n",
    "    end_time[\"text\"] = str(datetime.timedelta(seconds=vid_player.duration()))\n",
    "    \"\"\" updates the scale value \"\"\"\n",
    "    \"\"\" used to seek a specific timeframe \"\"\"\n",
    "def play_pause():\n",
    "    \"\"\" pauses and plays \"\"\"\n",
    "    vid_player.load('merge.mp4')\n",
    "    if vid_player.is_paused():\n",
    "        vid_player.play()\n",
    "\n",
    "    else:\n",
    "        vid_player.pause()\n",
    "\n",
    "\n",
    "def video_ended(event):\n",
    "    \"\"\" handle video ended \"\"\"\n",
    "    play_pause_btn[\"text\"] = \"Play\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f571f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkVideoPlayer import TkinterVideo\n",
    "import tkinter as tk\n",
    "from tkinter import font\n",
    "global arr\n",
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "from tkinter import *   \n",
    "from tkinter import *\n",
    "from threading import Thread\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "arr=\"\"\n",
    "top=tk.Tk()#for create frame\n",
    "top.title(\"Detect Sign Hand\")\n",
    "top.geometry(\"1200x1000\")\n",
    "#top.configure(bg='#FFEBC1')\n",
    "\n",
    "top.configure(bg='#f2d896')\n",
    "top.attributes('-fullscreen', True)\n",
    "\n",
    "\n",
    "new=Toplevel(top) \n",
    "new.withdraw()#to hide frame\n",
    "new.geometry(\"1200x1000\")\n",
    "new.configure(bg='#f2d896')\n",
    "new.attributes('-fullscreen', True)\n",
    "\n",
    "root=Toplevel(top)\n",
    "root.withdraw()#to hide frame\n",
    "root.geometry(\"1200x1000\")\n",
    "root.configure(bg='#f2d896')\n",
    "root.attributes('-fullscreen', True)\n",
    "\n",
    "\n",
    "guideFrame=Toplevel(top)\n",
    "guideFrame.withdraw()#to hide frame\n",
    "guideFrame.geometry(\"1200x1000\")\n",
    "guideFrame.configure(bg='#f2d896')\n",
    "guideFrame.attributes('-fullscreen', True)\n",
    "\n",
    "p1 = PhotoImage(file = '123.png')\n",
    "root.iconphoto(False, p1)\n",
    "new.iconphoto(False, p1)\n",
    "top.iconphoto(False, p1)\n",
    "guideFrame.iconphoto(False, p1)\n",
    "\n",
    "# Entry widget\n",
    "my_text1 = Entry(top,width=25,justify=CENTER, background=\"#79443B\",foreground='WHITE', font=('Droid Arabic Kufi', 50,'bold'), borderwidth=2,relief=RAISED )\n",
    "my_text1.insert(0, \"Hand Sign Language \")\n",
    "my_text1.pack(padx=50, pady=20)\n",
    "my_text2 = Entry(new, width=30, justify=CENTER, background=\"#79443B\",foreground='white', font=('Droid Arabic Kufi', 50,'bold'), borderwidth=2,relief=RAISED)\n",
    "my_text2.insert(0, \"Signature Hand Gestures\")\n",
    "my_text2.pack(padx=50, pady=20)\n",
    "\n",
    "my_text3 = Entry(root, width=30, justify=CENTER, background=\"#79443B\",foreground='white', font=('Droid Arabic Kufi', 50,'bold'), borderwidth=2,relief=RAISED)\n",
    "my_text3.insert(0, \"Converting Speech Into A Sign\")\n",
    "my_text3.pack(padx=50, pady=20)\n",
    "\n",
    "my_text4 = Entry(guideFrame, width=30, justify=CENTER, background=\"#79443B\",foreground='white', font=('Droid Arabic Kufi', 50,'bold'), borderwidth=2,relief=RAISED)\n",
    "my_text4.insert(0, \"Sign language in Arabic\")\n",
    "my_text4.pack(padx=50, pady=20)\n",
    "\n",
    "\n",
    "\n",
    "def change_to_cam():\n",
    "        top.withdraw()\n",
    "        new.deiconify()# to show frame\n",
    "        new.title(\"Detect Sign Hand\")\n",
    "        \n",
    "        bt = Button(new, text=\"open camera\",  bg='#BC544B', fg='black', command=main,height= 1, width=10)\n",
    "        bt['font'] = font2\n",
    "        bt.place(relx = 0.7, rely=0.3 , anchor = W)\n",
    "        \n",
    "        def backFrame():\n",
    "            bt.destroy()\n",
    "            b9.destroy()\n",
    "            top.deiconify()\n",
    "            new.withdraw()\n",
    "        b9 = Button(new, text=\"Back\",  bg='#BC544B', fg='#1F201F', command=backFrame,height= 1, width=10)\n",
    "        b9['font'] = font2\n",
    "        b9.place(relx = 0.7, rely=0.7 , anchor = W)\n",
    "         \n",
    "def change_to_speak():\n",
    "        top.withdraw()\n",
    "        root.deiconify()# to show frame\n",
    "        root.title(\"Detect Sign Hand\")\n",
    "        load_btn = Button(root, text=\"Speak\", bg='#BC544B', fg='black',  command=vedioSign,height= 1, width=10)\n",
    "        load_btn['font'] = font2\n",
    "        load_btn.place(relx=0.9, rely=0.3, anchor=NE)\n",
    "        play_pause_btn = tk.Button(root,text=\"repeat\", bg='#BC544B', fg='black',command=play_pause,height= 1, width=10)\n",
    "        play_pause_btn['font'] = font2\n",
    "        play_pause_btn.place(relx=0.9, rely=0.5, anchor=NE)\n",
    "        def backFrame():\n",
    "            load_btn.destroy()\n",
    "            b4.destroy()\n",
    "            play_pause_btn.destroy()\n",
    "            top.deiconify()\n",
    "            root.withdraw()\n",
    "        b4 = Button(root, text=\"Back\",  bg='#BC544B', fg='#1F201F', command=backFrame,height= 1, width=10)\n",
    "        b4['font'] = font2\n",
    "        b4.place(relx=0.9, rely=0.7, anchor=NE)\n",
    "\n",
    "def change_to_guide():\n",
    "        top.withdraw()\n",
    "        guideFrame.deiconify()# to show frame\n",
    "        guideFrame.title(\"Detect Sign Hand\")\n",
    "\n",
    "        def backFrame():\n",
    "            b7.destroy()\n",
    "            top.deiconify()\n",
    "            guideFrame.withdraw()\n",
    "        b7 = Button(guideFrame, text=\"Back\",  bg='#BC544B', fg='#1F201F', command=backFrame,height= 1, width=10)\n",
    "        b7['font'] = font2\n",
    "        b7.place(relx=0.9, rely=0.6, anchor=NE)\n",
    "\n",
    "def change_text():\n",
    "      var.set(\"\")\n",
    "        \n",
    "# Create fonts for making difference in the frame\n",
    "font1 = font.Font(family='Georgia', size='35', weight='bold')\n",
    "font2 = font.Font(family='Aerial', size='45')\n",
    "\n",
    "\n",
    "\n",
    "img =Image.open('T.jpg')\n",
    "resized = img.resize((300, 800), Image.ANTIALIAS)\n",
    "bg = ImageTk.PhotoImage(resized)\n",
    "labelm = Label(top, image=bg,borderwidth=0)\n",
    "labelm.place(relx=0.0, rely=0.1, anchor=NW)\n",
    "labelm1 = Label(top, image=bg,borderwidth=0)\n",
    "labelm1.place(relx=1, rely=0.1, anchor=NE)\n",
    "\n",
    "\n",
    "\n",
    "img2 =Image.open('st3.jpg')\n",
    "resized2 = img2.resize((800, 680), Image.ANTIALIAS)\n",
    "bg2 = ImageTk.PhotoImage(resized2)\n",
    "labelm2 = Label(guideFrame, image=bg2,borderwidth=0)\n",
    "labelm2.place(relx=0.0, rely=0.2, anchor=NW)\n",
    "\n",
    "img3 =Image.open('l.jpg')\n",
    "resized3 = img3.resize((150, 150), Image.ANTIALIAS)\n",
    "bg3 = ImageTk.PhotoImage(resized3)\n",
    "labelm3 = Label(top, image=bg3,borderwidth=0)\n",
    "labelm3.place(relx=0.0, rely=0.0, anchor=NW)\n",
    "labelm3 = Label(new, image=bg3,borderwidth=0)\n",
    "labelm3.place(relx=0.0, rely=0.0, anchor=NW)\n",
    "labelm3 = Label(root, image=bg3,borderwidth=0)\n",
    "labelm3.place(relx=0.0, rely=0.0, anchor=NW)\n",
    "labelm3 = Label(guideFrame, image=bg3,borderwidth=0)\n",
    "labelm3.place(relx=0.0, rely=0.0, anchor=NW)\n",
    "\n",
    "img4 =Image.open('lo.jpg')\n",
    "resized4 = img4.resize((150, 150), Image.ANTIALIAS)\n",
    "bg4 = ImageTk.PhotoImage(resized4)\n",
    "labelm5 = Label(top, image=bg4,borderwidth=0)\n",
    "labelm5.place(relx=0.9, rely=0.0, anchor=NW)\n",
    "labelm5 = Label(new, image=bg4,borderwidth=0)\n",
    "labelm5.place(relx=0.9, rely=0.0, anchor=NW)\n",
    "labelm5 = Label(root, image=bg4,borderwidth=0)\n",
    "labelm5.place(relx=0.9, rely=0.0, anchor=NW)\n",
    "labelm5 = Label(guideFrame, image=bg4,borderwidth=0)\n",
    "labelm5.place(relx=0.9, rely=0.0, anchor=NW)\n",
    "\n",
    "\n",
    "btn1 = Button(top, text=\"Scan Hand Sign\", bg='#BC544B', fg='black',command=change_to_cam,height= 1, width=15)\n",
    "btn1['font'] = font2\n",
    "btn1.place(relx=0.5, rely=0.3, anchor=CENTER)\n",
    "btn2 = Button(top, text=\"Speak\", bg='#BC544B', fg='black',  command=change_to_speak,height= 1, width=15)\n",
    "btn2['font'] = font2\n",
    "btn2.place(relx=0.5, rely=0.5, anchor=CENTER)\n",
    "\n",
    "btn3 = Button(top, text=\"Signal guide\", bg='#BC544B', fg='black',command=change_to_guide,height= 1, width=15)\n",
    "btn3['font'] = font2\n",
    "btn3.place(relx=0.5, rely=0.7, anchor=CENTER)\n",
    "\n",
    "exit_button = Button(top, text=\"EXIT\",bg='#BC544B', fg='#800517', command=top.destroy,height= 1, width=15)\n",
    "exit_button['font'] = font2\n",
    "exit_button.place(relx=0.5, rely=0.9, anchor=CENTER)\n",
    "\n",
    "T2=Label(root)\n",
    "\n",
    "btn4=Button(new, text=\"Change Text!\", bg='#BC544B', fg='black',command=change_text,height= 1, width=10)\n",
    "btn4['font'] = font2\n",
    "btn4.place(relx = 0.7, rely=0.5, anchor = W)      \n",
    "\n",
    "\n",
    "var = StringVar()    # create a string variable\n",
    "var.set(arr)      # set it to \"letter\"\n",
    "T= Label(new,textvariable = var,font =font2,fg='black',bg='#f2d896')   # display var \"letter\" as l2\n",
    "T.place(relx=0.6, rely=0.3, anchor=NE)      \n",
    " \n",
    "\n",
    "\n",
    "vid_player = TkinterVideo(scaled=True, master=root)\n",
    "vid_player.place(bordermode=OUTSIDE,relx = 0.1, rely=0.6 , anchor = W,height=600,width=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97044715",
   "metadata": {},
   "outputs": [],
   "source": [
    "top.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
